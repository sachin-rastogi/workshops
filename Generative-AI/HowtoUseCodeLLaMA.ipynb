{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This code demonstrates how to use the Hugging Face Hub and Transformers library to generate \"Code\" using a pre-trained language model. Below is a step-by-step summary of the code:","metadata":{}},{"cell_type":"markdown","source":"## Generate your Hugging Face token as per following links  \n- YT video : https://www.youtube.com/watch?v=Br7AcznvzSA\n- https://huggingface.co/docs/hub/en/security-tokens","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token = 'hf_xhqrqemGwVIMHtjxiIhckIbxyKViTmJC')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:14:12.424183Z","iopub.execute_input":"2024-11-25T04:14:12.424547Z","iopub.status.idle":"2024-11-25T04:14:13.028084Z","shell.execute_reply.started":"2024-11-25T04:14:12.424508Z","shell.execute_reply":"2024-11-25T04:14:13.027094Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!huggingface-cli whoami","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:14:15.391790Z","iopub.execute_input":"2024-11-25T04:14:15.392376Z","iopub.status.idle":"2024-11-25T04:14:17.041535Z","shell.execute_reply.started":"2024-11-25T04:14:15.392342Z","shell.execute_reply":"2024-11-25T04:14:17.040700Z"}},"outputs":[{"name":"stdout","text":"kakultech\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nfrom time import time\nimport transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:14:17.924683Z","iopub.execute_input":"2024-11-25T04:14:17.925708Z","iopub.status.idle":"2024-11-25T04:14:22.003174Z","shell.execute_reply.started":"2024-11-25T04:14:17.925671Z","shell.execute_reply":"2024-11-25T04:14:22.002259Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"model_id = \"meta-llama/CodeLlama-7b-hf\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:14:26.010829Z","iopub.execute_input":"2024-11-25T04:14:26.011652Z","iopub.status.idle":"2024-11-25T04:14:26.015403Z","shell.execute_reply.started":"2024-11-25T04:14:26.011616Z","shell.execute_reply":"2024-11-25T04:14:26.014363Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"time_1 = time()\ntokenizer = AutoTokenizer.from_pretrained(model_id)\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\nprint(f\"Tokenizer & pipeline: {round(time() - time_1)} sec.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:14:26.936400Z","iopub.execute_input":"2024-11-25T04:14:26.936746Z","iopub.status.idle":"2024-11-25T04:22:27.551244Z","shell.execute_reply.started":"2024-11-25T04:14:26.936718Z","shell.execute_reply":"2024-11-25T04:22:27.550263Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0cccb5834ec44d7a6bc4e28c0943913"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8db9663623b34b869bfe835c8ccb8daf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5776bd95b93b47dbb8f326c843528040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6af50e50d3d447c9bdbf7f174fe8ee34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e60a6177e0ea447e947dc9eec980834e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1b2dc77b4f442adb2907828dfb0cded"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"100ae02debe241768084796fbc881765"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc2fa5627c4446e9890e6631e1576264"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a800be8c69341e9b88a2551f6f8ac38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"270aeae2e83b4b718fb785d999ed1fcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7392476263134eada85e322586216051"}},"metadata":{}},{"name":"stdout","text":"Tokenizer & pipeline: 481 sec.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"prompt = 'Write the code for a function to compute the area of Square using Python.'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:24:06.499734Z","iopub.execute_input":"2024-11-25T04:24:06.500148Z","iopub.status.idle":"2024-11-25T04:24:06.505218Z","shell.execute_reply.started":"2024-11-25T04:24:06.500095Z","shell.execute_reply":"2024-11-25T04:24:06.504160Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"sequences = pipeline(\n    prompt,\n    do_sample=True,\n    top_k=10,\n    temperature=0.1,\n    top_p=0.95,\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n    max_length=200,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:24:11.718297Z","iopub.execute_input":"2024-11-25T04:24:11.718653Z","iopub.status.idle":"2024-11-25T04:24:21.484920Z","shell.execute_reply.started":"2024-11-25T04:24:11.718624Z","shell.execute_reply":"2024-11-25T04:24:21.484254Z"}},"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"for seq in sequences:\n    print(f\"Result: {seq['generated_text']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T05:04:51.433476Z","iopub.execute_input":"2024-11-23T05:04:51.433723Z","iopub.status.idle":"2024-11-23T05:04:51.438130Z","shell.execute_reply.started":"2024-11-23T05:04:51.433699Z","shell.execute_reply":"2024-11-23T05:04:51.437336Z"}},"outputs":[{"name":"stdout","text":"Result: Write the code for a function to compute the area of Square using Python.\n\ndef area_of_square(side):\n    return side * side\n\n# Example usage\nprint(area_of_square(5)) # Output: 25\n\n```\n\nExplanation:\n\nThe function `area_of_square` takes in a single argument `side`, which represents the length of the side of the square. The function then returns the area of the square, which is calculated by multiplying the length of the side by itself.\n\nIn the example usage, we call the function with the argument `5`, which means the square has a side length of 5 units. The function returns the area of the square, which is 25 square units.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}